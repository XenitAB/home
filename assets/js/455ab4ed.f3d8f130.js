"use strict";(self.webpackChunkhome=self.webpackChunkhome||[]).push([[6965],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return u}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),g=p(a),u=o,m=g["".concat(s,".").concat(u)]||g[u]||d[u]||r;return a?n.createElement(m,i(i({ref:t},c),{},{components:a})):n.createElement(m,i({ref:t},c))}));function u(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},278:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return p},metadata:function(){return c},toc:function(){return d},default:function(){return u}});var n=a(3117),o=a(102),r=(a(7294),a(3905)),i=a(4996),l=["components"],s={id:"observability",title:"Observability"},p=void 0,c={unversionedId:"xks/developer-guide/observability",id:"xks/developer-guide/observability",title:"Observability",description:"What is observability?",source:"@site/docs/xks/developer-guide/observability.md",sourceDirName:"xks/developer-guide",slug:"/xks/developer-guide/observability",permalink:"/docs/xks/developer-guide/observability",editUrl:"https://github.com/xenitab/xenitab.github.io/edit/main/docs/xks/developer-guide/observability.md",tags:[],version:"current",frontMatter:{id:"observability",title:"Observability"},sidebar:"docs",previous:{title:"Scheduling and Scaling",permalink:"/docs/xks/developer-guide/scheduling-scaling"},next:{title:"Networking",permalink:"/docs/xks/developer-guide/networking"}},d=[{value:"What is observability?",id:"what-is-observability",children:[],level:2},{value:"Datadog",id:"datadog",children:[{value:"Logging",id:"logging",children:[],level:3},{value:"Metrics",id:"metrics",children:[],level:3},{value:"Tracing",id:"tracing",children:[],level:3},{value:"Networkpolicy datadog",id:"networkpolicy-datadog",children:[],level:3}],level:2},{value:"Opentelemetry",id:"opentelemetry",children:[{value:"Metrics",id:"metrics-1",children:[],level:3},{value:"Logging",id:"logging-1",children:[],level:3},{value:"Tracing",id:"tracing-1",children:[{value:"Tail-based sampling",id:"tail-based-sampling",children:[],level:4}],level:3},{value:"Networkpolicy grafana agent",id:"networkpolicy-grafana-agent",children:[],level:3}],level:2}],g={toc:d};function u(e){var t=e.components,a=(0,o.Z)(e,l);return(0,r.kt)("wrapper",(0,n.Z)({},g,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"what-is-observability"},"What is observability?"),(0,r.kt)("p",null,"Within observability we normally talk about three pillars."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"metrics"),(0,r.kt)("li",{parentName:"ul"},"logging"),(0,r.kt)("li",{parentName:"ul"},"tracing")),(0,r.kt)("p",null,"Monitoring applications is an especially important feature when developing microservices\nand something that all developers of microservices needs to focus on."),(0,r.kt)("p",null,"We currently support two solutions to gather observability data in XKF, ",(0,r.kt)("a",{parentName:"p",href:"https://www.datadoghq.com"},"Datadog")," and the ",(0,r.kt)("a",{parentName:"p",href:"https://opentelemetry.io/"},"Opentelemetry")," stack which is an open-source solution."),(0,r.kt)("h2",{id:"datadog"},"Datadog"),(0,r.kt)("p",null,"When Datadog monitoring is used the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/DataDog/datadog-operator"},"Datadog Operator")," will be added to your cluster. On top of deploying a\nDatadog agent to every node to collect metrics, logs, and traces it also adds the ability to create Datadog monitors from the cluster. The Datadog\nagent handles all communication with the Datadog API meaning that individual applications do not have to deal with things such as authentication."),(0,r.kt)("h3",{id:"logging"},"Logging"),(0,r.kt)("p",null,"All logs written to ",(0,r.kt)("inlineCode",{parentName:"p"},"stdout")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"stderr")," from applications in the tenant namespace will be collected by the Datadog agents. This means that no additional\nconfiguration has to be done to the application, other than making sure the logs are written to the correct destination.\nThis means that ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl logs")," and Datadog will display the same information."),(0,r.kt)("p",null,"Check the official ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/agent/kubernetes/log/?tab=daemonset"},"Datadog Logging Documentation")," for more detailed information."),(0,r.kt)("h3",{id:"metrics"},"Metrics"),(0,r.kt)("p",null,"Datadog can collect Prometheus or OpenMetrics metrics exposed by your application.\nIn simple terms this means that the application needs to expose an endpoint which the Datadog agent can scrape to get the metrics.\nAll that is required is that the Pod contains annotations which tells Datadog where to find the metrics HTTP endpoint."),(0,r.kt)("p",null,"Given that your application is exposing metrics on port 8080 your pod should contain the following annotations."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'annotations:\n  ad.datadoghq.com/prometheus-example.instances: |\n    [\n      {\n        "prometheus_url": "http://%%host%%:8080/metrics"\n      }\n    ]\n')),(0,r.kt)("p",null,"Check the official ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/agent/kubernetes/prometheus/"},"Datadog Metrics Documentation")," for more detailed information."),(0,r.kt)("h3",{id:"tracing"},"Tracing"),(0,r.kt)("p",null,"Datadog tracing is done with Application Performance Monitoring (APM), which sends traces from an application to Datadog.\nFor traces to work the application needs to be configured with the language specific libraries.\nCheck the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/tracing/setup_overview/"},"Language Documentation"),"\nfor language specific instructions. Some of the languages that are supported are."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Golang"),(0,r.kt)("li",{parentName:"ul"},"C#"),(0,r.kt)("li",{parentName:"ul"},"Java"),(0,r.kt)("li",{parentName:"ul"},"Python")),(0,r.kt)("p",null,"Configure your Deployment with the ",(0,r.kt)("inlineCode",{parentName:"p"},"DD_AGENT_HOST")," environment for the APM agent to know where to send the traces."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-deployment.yaml"},"apiVersion: apps/v1\nkind: Deployment\nspec:\n  containers:\n    - env:\n        - name: DD_AGENT_HOST\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n")),(0,r.kt)("p",null,"Check the official ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/agent/kubernetes/apm/?tab=helm"},"Datadog Tracing Documentation")," for more detailed information."),(0,r.kt)("p",null,"To add tracing to Datadog's ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/synthetics/browser_tests"},"Browser Test")," results, add the URLs that the browser tests visits under UX Monitoring/Synthetic Settings/Integration Settings. See ",(0,r.kt)("a",{parentName:"p",href:"https://docs.datadoghq.com/synthetics/apm"},"Synthetic APM")," for more information. You can see a example on how to set this up below. By using a wildcard, multiple endpoints can be traced."),(0,r.kt)("img",{alt:"Browser Test URLs",src:(0,i.Z)("img/assets/xks/developer-guide/browser-test-urls.png")}),(0,r.kt)("h3",{id:"networkpolicy-datadog"},"Networkpolicy datadog"),(0,r.kt)("p",null,"When using XKF and your cluster has Datadog enabled the tenant namespace will automatically get a networkpolicy that allows egress for tracing and ingress for metrics."),(0,r.kt)("p",null,"You can view these rules by typing:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get networkpolicies -n <tenant-namespace>\n")),(0,r.kt)("h2",{id:"opentelemetry"},"Opentelemetry"),(0,r.kt)("p",null,"To gather opentelemetry data we rely on the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/grafana/agent"},"grafana agent operator"),".\nThe grafana agent operator deploys a grafana-agent in a central namespace configured as a part of XKF."),(0,r.kt)("p",null,"The grafana agent gathers both metrics and logs and is able to receive traces."),(0,r.kt)("h3",{id:"metrics-1"},"Metrics"),(0,r.kt)("p",null,"To gather metrics data we use servicemonitors or podmonitors that is managed in XKF using the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/prometheus-operator/prometheus-operator/"},"prometheus-operator"),"."),(0,r.kt)("p",null,"The prometheus-operator has a great ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md"},"getting started guide"),"\nbut if you want a quick example you can look below."),(0,r.kt)("p",null,"In order for the grafana agent to find the pod you have to put this exact label on the pod/service monitor yaml: ",(0,r.kt)("inlineCode",{parentName:"p"},"xkf.xenit.io/monitoring: tenant"),",\nor else the grafana agent will not find the rule to gather the metric."),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/"},"selectors")," is used to find ether the pod or the service that you want to monitor."),(0,r.kt)("p",null,"Use a podmonitor when you do not have a service in front of your pod.\nFor example this might be the case when your application does not use an HTTP endpoint to get requests."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-podmonitor.yaml"},"apiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: podmonitor-example\n  labels:\n    xkf.xenit.io/monitoring: tenant\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app1\n  podMetricsEndpoints:\n    - port: http-metrics\n")),(0,r.kt)("p",null,"In general use a servicemonitor when you have a service in front of your pod."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-servicemonitor.yaml"},"apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    xkf.xenit.io/monitoring: tenant\n  name: servicemonitor-example\nspec:\n  endpoints:\n  - interval: 60s\n    port: metrics\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: app1\n")),(0,r.kt)("p",null,"You can do a lot of configuration when it comes to metrics gathering but the above config will get you started."),(0,r.kt)("h3",{id:"logging-1"},"Logging"),(0,r.kt)("p",null,"To gather logs from your application you need to define a PodLogs object."),(0,r.kt)("p",null,"Just like metrics you have to define a label like ",(0,r.kt)("inlineCode",{parentName:"p"},"xkf.xenit.io/monitoring: tenant")," in your PodLogs.\nThe PodLogs CRD is created by the grafana agent operator and functions very similarly to how the prometheus operator works, especially when it comes to selectors.\nBelow you will find a very basic example that will scrape a single pod in the namespace where it is created."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-podlogs.yaml"},"apiVersion: monitoring.grafana.com/v1alpha1\nkind: PodLogs\nmetadata:\n  name: app1\n  labels:\n    xkf.xenit.io/monitoring: tenant\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app1\n  pipelineStages:\n    - cri: {}\n")),(0,r.kt)("p",null,"You can do a lot of configuration when it comes to log filtering using PodLogs. For example you can drop specific log types that you do not want to send to your long time storage.\nSadly the grafana agent operator does not supply great documentation around how to define this configuration in the operator.\nHowever, together with running ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl explain podlogs.monitoring.grafana.com.spec.pipelineStages")," on the cluster and\nreading the ",(0,r.kt)("a",{parentName:"p",href:"https://grafana.com/docs/loki/latest/clients/promtail/pipelines/"},"official documentation")," on how to create pipelines you can get a good understanding of how to create the configuration that you need."),(0,r.kt)("p",null,"If you do not have any needs to filter or do any custom config per application you can create a namespace-wide PodLogs gatherer."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-podlogs.yaml"},"apiVersion: monitoring.grafana.com/v1alpha1\nkind: PodLogs\nmetadata:\n  name: tenant-namespace-log\n  labels:\n    xkf.xenit.io/monitoring: tenant\nspec:\n  selector: {}\n  pipelineStages:\n    - cri: {}\n")),(0,r.kt)("h3",{id:"tracing-1"},"Tracing"),(0,r.kt)("p",null,"The tracing setup is a bit different compared to logging and metrics, instead of having some yaml file where you define how to gather metrics and logs from\nyour application, you instead push data to a central collector."),(0,r.kt)("p",null,"Opentelemetry supports both HTTP and gRPC communication to gather traces from your application."),(0,r.kt)("p",null,"To send HTTP data we use ",(0,r.kt)("inlineCode",{parentName:"p"},"4318")," and for gRPC we use ",(0,r.kt)("inlineCode",{parentName:"p"},"4317"),"."),(0,r.kt)("p",null,"Point your OpenTelemetry SDK to ",(0,r.kt)("a",{parentName:"p",href:"http://grafana-agent-traces.opentelemetry.svc.cluster.local:4318/v1/traces"},"http://grafana-agent-traces.opentelemetry.svc.cluster.local:4318/v1/traces"),"\nor ",(0,r.kt)("a",{parentName:"p",href:"http://grafana-agent-traces.opentelemetry.svc.cluster.local:4317/v1/traces"},"http://grafana-agent-traces.opentelemetry.svc.cluster.local:4317/v1/traces"),"."),(0,r.kt)("h4",{id:"tail-based-sampling"},"Tail-based sampling"),(0,r.kt)("p",null,"By default the grafana agent that is deployed by XKF forwards all traces without any special config to your service provider.\nThis can cause high costs thanks to the amount of data that is sent.\nYou can configure the agent to use ",(0,r.kt)("inlineCode",{parentName:"p"},"probabilistic sampling")," which grafana agent delivers their own solution for called ",(0,r.kt)("a",{parentName:"p",href:"https://grafana.com/docs/tempo/latest/grafana-agent/tail-based-sampling/"},"tail-based sampling"),", which can help you solve this issue."),(0,r.kt)("p",null,"To setup a custom agent with tail-based sampling you can setup your own trace agent with the custom config that you want and then have it forward all the traffic to our central trace agent in the ",(0,r.kt)("inlineCode",{parentName:"p"},"opentelemetry")," namespace.\nBelow you can find a simple example configmap that you can use together with your trace agent to send data to the central agent."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-trace-agent-configmap.yaml"},'kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: grafana-agent-traces\ndata:\n  agent.yaml: |\n    tempo:\n      configs:\n        - name: default\n          remote_write:\n            - endpoint: "grafana-agent-traces.grafana-agent.svc.cluster.local:4317"\n              insecure: true\n          receivers:\n            otlp:\n              protocols:\n                http: {}\n                grpc: {}\n          tail_sampling:\n            # policies define the rules by which traces will be sampled. Multiple policies\n            # can be added to the same pipeline.\n            # For more information: https://grafana.com/docs/agent/latest/configuration/traces-config/\n            # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/processor/tailsamplingprocessor\n            policies:\n              - probabilistic: {sampling_percentage: 10}\n              - status_code: {status_codes: [ERROR, UNSET]}\n')),(0,r.kt)("h3",{id:"networkpolicy-grafana-agent"},"Networkpolicy grafana agent"),(0,r.kt)("p",null,"When using XKF and your cluster have enabled the grafana agent your tenant namespace will automatically get a networkpolicy that allows\nincoming metrics gathering and egress for tracing."),(0,r.kt)("p",null,"You can view these rules by typing:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get networkpolicies -n <tenant-namespace>\n")))}u.isMDXComponent=!0}}]);