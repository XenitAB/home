"use strict";(self.webpackChunkhome=self.webpackChunkhome||[]).push([[401],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return u}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),h=c(n),u=a,m=h["".concat(l,".").concat(u)]||h[u]||p[u]||i;return n?r.createElement(m,o(o({ref:t},d),{},{components:n})):r.createElement(m,o({ref:t},d))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var c=2;c<i;c++)o[c]=n[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},3919:function(e,t,n){function r(e){return!0===/^(\w*:|\/\/)/.test(e)}function a(e){return void 0!==e&&!r(e)}n.d(t,{b:function(){return r},Z:function(){return a}})},4996:function(e,t,n){n.d(t,{C:function(){return i},Z:function(){return o}});var r=n(2263),a=n(3919);function i(){var e=(0,r.Z)().siteConfig,t=(e=void 0===e?{}:e).baseUrl,n=void 0===t?"/":t,i=e.url;return{withBaseUrl:function(e,t){return function(e,t,n,r){var i=void 0===r?{}:r,o=i.forcePrependBaseUrl,s=void 0!==o&&o,l=i.absolute,c=void 0!==l&&l;if(!n)return n;if(n.startsWith("#"))return n;if((0,a.b)(n))return n;if(s)return t+n;var d=n.startsWith(t)?n:t+n.replace(/^\//,"");return c?e+d:d}(i,n,e,t)}}}function o(e,t){return void 0===t&&(t={}),(0,i().withBaseUrl)(e,t)}},639:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return c},metadata:function(){return d},toc:function(){return p},default:function(){return u}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=n(4996),s=["components"],l={id:"networking",title:"Networking"},c=void 0,d={unversionedId:"xks/developer-guide/networking",id:"xks/developer-guide/networking",isDocsHomePage:!1,title:"Networking",description:"Network Policies",source:"@site/docs/xks/developer-guide/networking.md",sourceDirName:"xks/developer-guide",slug:"/xks/developer-guide/networking",permalink:"/docs/xks/developer-guide/networking",editUrl:"https://github.com/xenitab/xenitab.github.io/edit/main/docs/xks/developer-guide/networking.md",tags:[],version:"current",frontMatter:{id:"networking",title:"Networking"},sidebar:"docs",previous:{title:"Flux",permalink:"/docs/xks/developer-guide/flux"},next:{title:"Working with XKF from Windows",permalink:"/docs/xks/developer-guide/wsl2"}},p=[{value:"Network Policies",id:"network-policies",children:[{value:"Examples",id:"examples",children:[{value:"Allow Internet Egress",id:"allow-internet-egress",children:[],level:4},{value:"Allow Ingress Nginx",id:"allow-ingress-nginx",children:[],level:4},{value:"Allow Cross Namespace",id:"allow-cross-namespace",children:[],level:4}],level:3},{value:"Debugging",id:"debugging",children:[],level:3}],level:2},{value:"Ingress",id:"ingress",children:[{value:"Private Ingress",id:"private-ingress",children:[],level:3},{value:"Nginx Configuration",id:"nginx-configuration",children:[],level:3},{value:"Debugging",id:"debugging-1",children:[],level:3}],level:2},{value:"Linkerd",id:"linkerd",children:[{value:"Get Started",id:"get-started",children:[],level:3},{value:"FAQ",id:"faq",children:[{value:"Is all network traffic encrypted?",id:"is-all-network-traffic-encrypted",children:[],level:4},{value:"What overhead can I expect?",id:"what-overhead-can-i-expect",children:[],level:4}],level:3}],level:2}],h={toc:p};function u(e){var t=e.components,n=(0,a.Z)(e,s);return(0,i.kt)("wrapper",(0,r.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"network-policies"},"Network Policies"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/services-networking/network-policies/"},"Network Policies")," in Kubernetes add the ability to allow and deny network traffic from specific pods and namespaces. Both\negress traffic from a Pod and ingress traffic to a Pod can be controlled. In a vanilla Kubernetes cluster all traffic between all namespaces is allowed by default. This is not the case in XKS. Out of\nthe box in XKS all tenant namespaces have a default deny rule added to them. This default deny rule will block any traffic going between namespaces. It will deny both ingress traffic from other\nnamespaces and egress traffic to other namespaces. All traffic within the namespace between Pods is allowed. The reasoning behind this setup is that Pods should not have more network access than they\nrequire to function, as it reduces the blast radius in case of an exploit."),(0,i.kt)("img",{alt:"Default Deny Network Policy",src:(0,o.Z)("img/assets/xks/developer-guide/network-policy-default-deny.jpg")}),(0,i.kt)("p",null,"The default deny Network Policy contains an exception for traffic destined to the clusters DNS service. Without this exception DNS resolution would not work. The pod selector in the Network Policy is\nempty, this means that the Network Policy will apply for all Pods in the namespace."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny\n  namespace: tenant\nspec:\n  egress:\n    - ports:\n        - port: 53\n          protocol: UDP\n      to:\n        - namespaceSelector: {}\n          podSelector:\n            matchLabels:\n              k8s-app: kube-dns\n    - to:\n        - podSelector: {}\n  ingress:\n    - from:\n        - podSelector: {}\n  podSelector: {}\n  policyTypes:\n    - Ingress\n    - Egress\n")),(0,i.kt)("p",null,"There may come a time when you have to create new Network Policies to allow specific Pods traffic as the default can be pretty restrictive. A common situation when this is required is when a Pod needs to\ncommunicate to the public Internet, or communicate between tenant namespaces. When creating new Network Policies make sure that you do not open up more than actually required. A good source of example\nNetwork Policies is the Github repository ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/ahmetb/kubernetes-network-policy-recipes"},"kubernetes-network-policy-recipes"),". It contains a lot of good examples with diagrams and\ndescriptions. The examples on this page contains the most common use cases to make things simpler for you."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"A helpful tool when create new Network Policies is the ",(0,i.kt)("a",{parentName:"p",href:"https://editor.cilium.io/"},"Cilium Network Policy Editor"),".")),(0,i.kt)("h3",{id:"examples"},"Examples"),(0,i.kt)("h4",{id:"allow-internet-egress"},"Allow Internet Egress"),(0,i.kt)("p",null,"A common scenario is opening up traffic to the public Internet. A current limitation with Network Policies today is that it is not possible to create egress rules based on DNS names. This means that\nthe simplest solution is to allow traffic to all public IPs as trying to resolve the DNS to an IP would only work short term."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-internet-egress\nspec:\n  egress:\n    - to:\n        - ipBlock:\n            cidr: 0.0.0.0/0\n  podSelector:\n    matchLabels:\n      app: foo\n  policyTypes:\n    - Egress\n")),(0,i.kt)("h4",{id:"allow-ingress-nginx"},"Allow Ingress Nginx"),(0,i.kt)("p",null,"Traffic from the ingress controller has to be explicitly allowed as no traffic is allowed from outside the namespace by default. This can be considered a fail safe to protect against accidental\nIngress creation where an application is exposed to the internet when that was not the intent. It is enough to allow ingress from the ingress controller even if the traffic actually originates from\noutside the cluster."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-ingress-controller\nspec:\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: ingress-nginx\n  podSelector:\n    matchLabels:\n      app: foo\n  policyTypes:\n    - Ingress\n")),(0,i.kt)("h4",{id:"allow-cross-namespace"},"Allow Cross Namespace"),(0,i.kt)("p",null,"When allowing network traffic across tenant namespaces considerations have to be made for the default deny Network Policy in both namespaces. An allow rule has to be created to allow the source\nnamespace (the side initating the connection) to send traffic to the other namespace. The destination namespace has to allow traffic from the source namespace. The first Network Policy should be used\nin the source namespace and the second should be used in the destination namespace."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-egress-to-destination\n  namespace: source\nspec:\n  egress:\n    - to:\n        - namespaceSelector:\n            matchLabels:\n              name: destination\n          podSelector:\n            matchLabels:\n              app: bar\n  podSelector:\n    matchLabels:\n      app: foo\n  policyTypes:\n    - Egress\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-ingress-from-source\n  namespace: destination\nspec:\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: source\n          podSelector:\n            matchLabels:\n              app: foo\n  podSelector:\n    matchLabels:\n      app: bar\n  policyTypes:\n    - Ingress\n")),(0,i.kt)("h3",{id:"debugging"},"Debugging"),(0,i.kt)("p",null,"TBD"),(0,i.kt)("h2",{id:"ingress"},"Ingress"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/services-networking/ingress/"},"Ingress")," in Kubernetes is used to allow network traffic from the outside the cluster to reach Pods inside the cluster. Ingress works\nas a layer on top of Kubernetes Services by exposing the Service with a hostname. All Ingress traffic is Layer 7 routed meaning that traffic is routed based on the host header in the HTTP request. This\nalso means that Ingress only works with HTTP traffic. Doing it this way means that only a single load balancer is required reducing cost compared to running multiple load balancers, one per Ingress."),(0,i.kt)("img",{alt:"Ingress Overview",src:(0,o.Z)("img/assets/xks/developer-guide/ingress-overview.jpg")}),(0,i.kt)("p",null,"XKS comes with everything pre-configured for Ingress to work. The cluster will either have a single ",(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.github.io/ingress-nginx/"},"Nginx Ingress Controller")," which is exposed to the\npublic Internet or two controllers where one is public and one is private. On top of that the cluster is configured with ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/external-dns"},"External DNS")," which creates\nDNS records and ",(0,i.kt)("a",{parentName:"p",href:"https://cert-manager.io/docs/"},"Cert Manager")," which deals with certificate creation and renewal. Together these three tools offer an automated solution where the complexity of DNS and\ncertificates are not handled by the application. The recommendation is to always enabled TLS for all Ingress resources no matter how small the service is. Updating a certificate is\nquick and easy so there is no reason not to. Every XKS cluster comes with a preconfigured Cluster Issuer which will provision certificates from ",(0,i.kt)("a",{parentName:"p",href:"https://letsencrypt.org/"},"Let's Encrypt"),"."),(0,i.kt)("p",null,"Start off with creating a Certificate resource for your Ingress. It is possible to have Cert Manager automatically create a Certificate when an Ingress resource is created. This however has the\ndownside that every Ingress resource will receive its own Certificate. Lets Encrypt has ",(0,i.kt)("a",{parentName:"p",href:"https://letsencrypt.org/docs/rate-limits/"},"rate limits")," for the same domain, if one were to create a\nCertificate per ingress that rate limit would be hit pretty quickly. That is why it is better to create a shared Certificate per tenant namespace with multiple DNS names instead. Each DNS name will be\npresent in the Certificate so that it can be used for multiple Ingress resources. When the Certificate is provisioned it will be written to a Secret."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: shared\n  namespace: tenant\nspec:\n  issuerRef:\n    group: cert-manager.io\n    kind: ClusterIssuer\n    name: letsencrypt\n  dnsNames:\n    - app-one.example.com\n    - app-two.example.com\n  secretName: shared-cert\n")),(0,i.kt)("p",null,"To complete the ingress configuration an Ingress resource has to be created. The Ingress resource defines the Service where the traffic should be routed to and the DNS name which should resolve to\nthat Service. An additional configuration is the TLS configuration which configures the certificate to use. Cert Manager writes the certificate data to a Secret which is configured in the Certificate\n",(0,i.kt)("inlineCode",{parentName:"p"},"secretName"),". That same Secret should be referenced in the TLS configuration. A DNS record will be automatically created when the Ingress is applied to the cluster."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-one\n  namespace: tenant\nspec:\n  rules:\n    - host: app-one.example.com\n      http:\n        paths:\n          - path: /\n            backend:\n              service:\n                name: app-one\n                port:\n                  name: http\n  tls:\n    - hosts:\n        - app-one.example.com\n      secretName: shared-cert\n")),(0,i.kt)("h3",{id:"private-ingress"},"Private Ingress"),(0,i.kt)("p",null,"TBD"),(0,i.kt)("h3",{id:"nginx-configuration"},"Nginx Configuration"),(0,i.kt)("p",null,"It is useful to be aware of ",(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#annotations"},"annotation configuration")," in the Nginx ingress controller.\nSometimes a specific Ingress requires custom behavior that is not default in the ingress controller, this behavior can be customized with the help of annotations for a specific Ingress resource.\nFor example changing the client body buffer size may be useful if the header size in a request is larger than the buffer."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: foo\n  namespace: bar\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/client-body-buffer-size: 1M\nspec:\n  rules:\n    - host: foo.dev.example.com\n      http:\n        paths:\n          - backend:\n              serviceName: foo\n              servicePort: http\n  tls:\n    - hosts:\n        - foo.dev.example.com\n")),(0,i.kt)("h3",{id:"debugging-1"},"Debugging"),(0,i.kt)("p",null,"TBD"),(0,i.kt)("h2",{id:"linkerd"},"Linkerd"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://linkerd.io/"},"Linkerd")," is an optional service mesh that can be added to XKS. The component is opt-in as it adds a certain amount of overhead,\nso unless it has been requested Linkerd will not be present in XKS. A service mesh extends the networking functionality in a Kubernetes cluster. It is\nuseful when features such as end-to-end encryption or GRPC load balancing is required. Linkerd will automatically handle TCP loadbalancing so when\nGRPC is used Linkerd will detect this and loadbalance between instances of GRPC servers."),(0,i.kt)("p",null,"Refer to the ",(0,i.kt)("a",{parentName:"p",href:"https://linkerd.io/2.10/overview/"},"official documentation")," for documentation that may be missing from this page."),(0,i.kt)("p",null,"Linkerd works by injecting a sidecar into every Pod which uses Linkerd. All network requests have to be sent through the sidecar which will then be\nresponsible for forwarding it. The sidecar will hanlde things like traffic encryption before sending the packets outside of the node."),(0,i.kt)("img",{alt:"Linkerd Overview",src:(0,o.Z)("img/assets/xks/developer-guide/linkerd-overview.jpg")}),(0,i.kt)("h3",{id:"get-started"},"Get Started"),(0,i.kt)("p",null,"To enable sidecar injection the Pod has to have the annotation ",(0,i.kt)("inlineCode",{parentName:"p"},"linkerd.io/inject: enabled")," added to it. A common mistake when enabling Linkerd is\nthat the annotation is added to Deployment and not the Pod template, make sure that you do not do this as the sidecar will not be injected if\nyou do."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkerd-test\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkerd-test\n  template:\n    metadata:\n      annotations:\n        linkerd.io/inject: enabled\n      labels:\n        app: linkerd-test\n    spec:\n      containers:\n        - name: linkerd-test\n          image: alpine:latest\n          ports:\n            - containerPort: 8080\n              name: http\n              protocol: TCP\n")),(0,i.kt)("p",null,"Eventually a Pod should be created. An important detail is that there should be two containers in the Pod. One container should be the one defined in\nthe Deployment and the other one the Linkerd sidecar. This can be verified by getting the Pods containers."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'$ kubectl get pods <POD_NAME> -o jsonpath="{.spec.containers[*].name}"\nlinkerd-test linkerd-proxy\n')),(0,i.kt)("p",null,"With the sidecar added all traffic going out of the container will automatically be proxied through the sidecar."),(0,i.kt)("h3",{id:"faq"},"FAQ"),(0,i.kt)("h4",{id:"is-all-network-traffic-encrypted"},"Is all network traffic encrypted?"),(0,i.kt)("p",null,"No, it depends on the traffic type and is something that should be verified rather than assumed. More information can be found in the ",(0,i.kt)("a",{parentName:"p",href:"https://linkerd.io/2.10/features/automatic-mtls/#"},"Linkerd documentation"),"."),(0,i.kt)("h4",{id:"what-overhead-can-i-expect"},"What overhead can I expect?"),(0,i.kt)("p",null,"Each Pod will at minimum consume an additional 10 MB due to the extra sidecar and the number can grow as traffic increases."))}u.isMDXComponent=!0}}]);